{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Classficiation\n",
    ">- BMI 지수에 대한 데이터로 학습 후 예측까지 진행해본다.\n",
    ">- BMI 지수는 키와 몸무게를 가지고 저체중, 정상, 과체중, 비만을 판단하는 지수\n",
    ">- BMI = 자신의 몸무게 (kg) / 키의 제곱 (m)\n",
    ">  - 18.5 이하 =>저체중\n",
    ">  - 18.5 ~ 23 => 정상\n",
    ">  - 23 ~ 25 => 과체중\n",
    ">  - 25 ~ 비만\n",
    ">- BMI 지수를 조사한 데이터를 학습하여 예측한다. 3가지로 분류됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn으로 Multinomial Classificiation 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  height  weight\n",
       "0          1     188      71\n",
       "1          2     161      68\n",
       "2          0     178      52\n",
       "3          2     136      63\n",
       "4          1     145      52\n",
       "...      ...     ...     ...\n",
       "19995      0     163      48\n",
       "19996      2     139      70\n",
       "19997      1     150      48\n",
       "19998      1     189      69\n",
       "19999      1     142      41\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### cross validation ###\n",
      "### cross validation score ###\n",
      "score : [0.98       0.98642857 0.985      0.97642857 0.98642857 0.98428571\n",
      " 0.98714286 0.97714286 0.97714286 0.98642857]\n",
      "평균 : 0.9826428571428572\n",
      "Model의 최종 Accuracy : 0.9845\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Classficiation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# stats 서브패키지는 확률분포 분석 기능 제공\n",
    "from scipy import stats \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('./data/bmi.csv', skiprows=3)\n",
    "display(df)\n",
    "\n",
    "# 결측치 확인 - 없음\n",
    "df.isnull().sum()\n",
    "\n",
    "# 이상치 확인\n",
    "zscore = 1.8\n",
    "\n",
    "# height의 이상치 확인 => 셋 다 없음\n",
    "# df.loc[np.abs(stats.zscore(df['height'])) >= zscore, :]\n",
    "# df.loc[np.abs(stats.zscore(df['weight'])) >= zscore, :]\n",
    "# df.loc[np.abs(stats.zscore(df['label'])) >= zscore, :]\n",
    "\n",
    "# Data Split\n",
    "# training, test 7:3 분리\n",
    "# 나중에 Train부분은 k-fold cross validation을 진행한다.\n",
    "\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df[['height', 'weight']], df['label'], test_size=0.3, random_state=0)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()  # scaler 객체를 생성한다.\n",
    "scaler.fit(x_data_train) # scaler 객체에 최대, 최소와 같은 정보가 들어간다.\n",
    "\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "del x_data_train  # 혼동을 방지하기 위해 변수 삭제\n",
    "del x_data_test  \n",
    "\n",
    "# sklearn 구현은 매우 간단!\n",
    "# Model을 생성하고, 학습시키고, 예측한다.\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_data_train_norm, t_data_train)\n",
    "\n",
    "# model의 정확도 측정\n",
    "# cross validation\n",
    "kfold = 10\n",
    "kfold_score = cross_val_score(model, x_data_train_norm, t_data_train, cv=kfold)\n",
    "print('### cross validation ###')\n",
    "print('### cross validation score ###')\n",
    "print('score : {}'.format(kfold_score))\n",
    "print('평균 : {}'.format(kfold_score.mean()))\n",
    "\n",
    "# 최종모델평가\n",
    "predict_val = model.predict(x_data_test_norm) # 테스트 데이터로 예측값을 구한다.\n",
    "acc = accuracy_score(predict_val, t_data_test)\n",
    "print('Model의 최종 Accuracy : {}'.format(acc))\n",
    "\n",
    "# Predict\n",
    "height = 188\n",
    "weight = 78\n",
    "my_state = [[height, weight]]\n",
    "my_state_val = model.predict(scaler.transform(my_state))\n",
    "print(my_state_val) # [1] -> 정상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tesorflow로 Multinomial Classificiation 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  height  weight\n",
       "0          1     188      71\n",
       "1          2     161      68\n",
       "2          0     178      52\n",
       "3          2     136      63\n",
       "4          1     145      52\n",
       "...      ...     ...     ...\n",
       "19995      0     163      48\n",
       "19996      2     139      70\n",
       "19997      1     150      48\n",
       "19998      1     189      69\n",
       "19999      1     142      41\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/bmi.csv', skiprows=3)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "### 학습이 시작된다. ###\n",
      "Loss : 1.2564572095870972\n",
      "Loss : 0.2887102961540222\n",
      "Loss : 0.22310075163841248\n",
      "Loss : 0.19122354686260223\n",
      "Loss : 0.17133188247680664\n",
      "Loss : 0.1573738008737564\n",
      "Loss : 0.14687514305114746\n",
      "Loss : 0.13860520720481873\n",
      "Loss : 0.13187086582183838\n",
      "Loss : 0.12624940276145935\n",
      "### 학습이 종료된다.###\n",
      "### 학습이 시작된다. ###\n",
      "Loss : 0.8981712460517883\n",
      "Loss : 0.26843613386154175\n",
      "Loss : 0.20586833357810974\n",
      "Loss : 0.1754659116268158\n",
      "Loss : 0.15666088461875916\n",
      "Loss : 0.14358223974704742\n",
      "Loss : 0.13382002711296082\n",
      "Loss : 0.12617820501327515\n",
      "Loss : 0.11998720467090607\n",
      "Loss : 0.11484046280384064\n",
      "### 학습이 종료된다.###\n",
      "### 학습이 시작된다. ###\n",
      "Loss : 1.0913689136505127\n",
      "Loss : 0.29898032546043396\n",
      "Loss : 0.23251324892044067\n",
      "Loss : 0.20037376880645752\n",
      "Loss : 0.1804378628730774\n",
      "Loss : 0.16651469469070435\n",
      "Loss : 0.1560787558555603\n",
      "Loss : 0.14787890017032623\n",
      "Loss : 0.14121384918689728\n",
      "Loss : 0.1356564462184906\n",
      "### 학습이 종료된다.###\n",
      "### 학습이 시작된다. ###\n",
      "Loss : 0.8923856616020203\n",
      "Loss : 0.28808844089508057\n",
      "Loss : 0.21965719759464264\n",
      "Loss : 0.1859416514635086\n",
      "Loss : 0.1649031788110733\n",
      "Loss : 0.15019038319587708\n",
      "Loss : 0.13917024433612823\n",
      "Loss : 0.1305249035358429\n",
      "Loss : 0.12351295351982117\n",
      "Loss : 0.11768021434545517\n",
      "### 학습이 종료된다.###\n",
      "### 학습이 시작된다. ###\n",
      "Loss : 1.18339204788208\n",
      "Loss : 0.2931476831436157\n",
      "Loss : 0.2233366221189499\n",
      "Loss : 0.18957221508026123\n",
      "Loss : 0.16861818730831146\n",
      "Loss : 0.15398569405078888\n",
      "Loss : 0.14302600920200348\n",
      "Loss : 0.13442343473434448\n",
      "Loss : 0.12744039297103882\n",
      "Loss : 0.12162692099809647\n",
      "### 학습이 종료된다.###\n",
      "CrossValidation 결과 : [0.9866667, 0.97833335, 0.9825, 0.98333335, 0.97333336]\n",
      "CrossValidation 최종 결과 : 0.9808333516120911\n",
      "### 학습이 시작된다. ###\n",
      "Loss : 0.8983460068702698\n",
      "Loss : 0.20564807951450348\n",
      "Loss : 0.16245803236961365\n",
      "Loss : 0.1428089588880539\n",
      "Loss : 0.1310224086046219\n",
      "Loss : 0.12295746058225632\n",
      "Loss : 0.11699065566062927\n",
      "Loss : 0.1123417392373085\n",
      "Loss : 0.10858340561389923\n",
      "Loss : 0.10545945912599564\n",
      "### 학습이 종료된다.###\n",
      "최종 정확도 : 0.9829999804496765\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "# BMI Multinomial Example\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler # Normalization\n",
    "from sklearn.model_selection import train_test_split # train, test 데이터 분리\n",
    "from sklearn.model_selection import KFold # cross validation\n",
    "\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/bmi.csv', skiprows=3)\n",
    "\n",
    "# 결측치와 이상치 확인 및 처리\n",
    "# 이상 없음\n",
    "\n",
    "# Data Split\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df[['height','weight']], df['label'], test_size=0.3, random_state=0)\n",
    "\n",
    "# 7:3 비율로 train과 test 데이터를 분리했다.\n",
    "# x_data_test, t_data_test 두개는 맨 끝에서 모델의 최종 Accuracy를 측정할 때 한번 사용한다.\n",
    "\n",
    "# Normalizaion 진행 (Min-Max Scaling)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train) # 나중에 scaling을 하기 위한 정보를 scaler에게 세팅\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "del x_data_train # 에러를 방지하기 위해 사용하지 않는 변수 삭제\n",
    "del x_data_test\n",
    "\n",
    "\n",
    "t_data_train\n",
    "# 정답에 해당하는 t_data_train을 살펴보니 Multinomial이다.\n",
    "# One hot encoding으로 데이터를 변환시켜야 한다.\n",
    "\n",
    "# 0 -> 1 0 0 \n",
    "# 1 -> 0 1 0 \n",
    "# 2 -> 0 0 1 \n",
    "# 종류 3가지 => Logistic 3개 => depth 3\n",
    "# Numpy를 이용한 로직 처리와, Tensorflow API를 이용하는 방법이 있는데 후자 선택.\n",
    "\n",
    "# Tensorflow node를 실행하기 위해 session이 필요하다.\n",
    "sess = tf.Session()\n",
    "\n",
    "# 우리가 사용할 label(t_data)을 one hot encoding 형태로 변환\n",
    "t_data_train_onehot = sess.run(tf.one_hot(t_data_train, depth=3))\n",
    "t_data_test_onehot = sess.run(tf.one_hot(t_data_test, depth=3))\n",
    "\n",
    "del t_data_train  # 에러를 방지하기 위해 사용하지 않는 변수 삭제\n",
    "del t_data_test\n",
    "\n",
    "# 지금까지 위에서 x_data_train_norm, t_data_train_onehot을 만들었다.\n",
    "# training data set을 준비했다.\n",
    "\n",
    "# 데이터가 준비 되었으니 Tensorflow Graph를 그려보자\n",
    "\n",
    "# Placeholder\n",
    "# shape=[None, n] => 행은 상관 없음\n",
    "X = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None, 3], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "# X, T의 shape을 이용한 행렬 연산으로 수행되기 위해 \n",
    "# W: 각각의 열이 logistic 1개에 해당 => 3개가 뭉쳐있음\n",
    "W = tf.Variable(tf.random.normal([2, 3]), name='weight') # 2가 키, 몸무게인가?\n",
    "b = tf.Variable(tf.random.normal([3]), name='bias')\n",
    "\n",
    "# Hypothesis (Model)\n",
    "logit = tf.matmul(X, W) + b\n",
    "H = tf.nn.softmax(logit)  # tf.sigmoid() 대신\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, \n",
    "                                                                 labels=T))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "# 반복학습하는 함수\n",
    "# parameter\n",
    "num_of_epoch = 1000\n",
    "batch_size = 100 # 한번에 학습할 x_data와 t_data의 행의 수\n",
    "\n",
    "\n",
    "def run_train(sess, train_x, train_t):\n",
    "    print('### 학습이 시작된다. ###')\n",
    "    # session과 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_batch = int(train_x.shape[0] / batch_size)  # (14000, 2)[0] => 14000\n",
    "    \n",
    "    for step in range(num_of_epoch):\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_t = train_t[i*batch_size:(i+1)*batch_size]\n",
    "            _, loss_val = sess.run([train, loss], \n",
    "                                   feed_dict={X: batch_x,\n",
    "                                              T: batch_t})\n",
    "        if step % 100 == 0:\n",
    "            print('Loss : {}'.format(loss_val))\n",
    "        \n",
    "    print('### 학습이 종료된다.###')\n",
    "            \n",
    "        \n",
    "# Accuracy (정확도 측정)   #    0    1     2   일 확률\n",
    "predict = tf.argmax(H, 1)  # [[0.5  0.4  0.1]] 입력한 값에 대한 예측 중 가장 큰 값을 알아냄\n",
    "                           # 2차원이기에 axis 지정, axis=1 열방향 가로 방향\n",
    "    \n",
    "correct = tf.equal(predict, tf.argmax(T, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "    \n",
    "\n",
    "# 1. 학습을 진행하고 Training data로 validation 수행 - 의미 없지만 오버피팅 확인\n",
    "# 학습진행\n",
    "# run_train(sess, x_data_train_norm, t_data_train_onehot)\n",
    "# # Accuracy 측정 (Training data로 validation 수행)\n",
    "# result = sess.run(accuracy, feed_dict={X:x_data_train_norm,\n",
    "#                               T:t_data_train_onehot})\n",
    "\n",
    "# print('Training data로 validation한 정확도 : {}'.format(result))\n",
    "\n",
    "\n",
    "# 2. 이렇게 하는 것 보다는 Cross Validation을 하는게 좋다.\n",
    "# Cross Validation\n",
    "cv = 5  # [훈련, 검증] => 5 set가 만들어 진다.\n",
    "results = []  # 5 set에 대한 accuracy를 구해서 liast 안에 넣는다.\n",
    "kf = KFold(n_splits=cv, shuffle=True)\n",
    "\n",
    "for training_idx, validation_idx in kf.split(x_data_test_norm):\n",
    "    # training_idx : 결국은 index 값을 알아온다.\n",
    "    train_x = x_data_train_norm[training_idx]    # Fancy indexing\n",
    "    train_t = t_data_train_onehot[training_idx]  # Fancy indexing\n",
    "    \n",
    "    valid_x = x_data_train_norm[validation_idx]\n",
    "    valid_t = t_data_train_onehot[validation_idx]\n",
    "    \n",
    "    run_train(sess, train_x, train_t)\n",
    "    results.append(sess.run(accuracy,\n",
    "                           feed_dict={X:valid_x,\n",
    "                                      T:valid_t}))\n",
    "    \n",
    "print('CrossValidation 결과 : {}'.format(results))\n",
    "print('CrossValidation 최종 결과 : {}'.format(np.mean(results)))\n",
    "\n",
    "\n",
    "# 3. 최종 accuracy 확인\n",
    "# 학습진행\n",
    "run_train(sess, x_data_train_norm, t_data_train_onehot)\n",
    "# Accuracy 측정\n",
    "result = sess.run(accuracy, feed_dict={X:x_data_test_norm,\n",
    "                              T:t_data_test_onehot})\n",
    "\n",
    "print('최종 정확도 : {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8375     0.95555556]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "height = 187\n",
    "weight = 78\n",
    "\n",
    "my_state = [[height, weight]]\n",
    "my_state_scaled = scaler.transform(my_state)\n",
    "print(my_state_scaled)\n",
    "\n",
    "result = sess.run(H, feed_dict={X:my_state_scaled})\n",
    "print(np.argmax(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
