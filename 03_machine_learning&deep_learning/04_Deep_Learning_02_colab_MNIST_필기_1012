{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"colab_MNIST_필기_1012","provenance":[{"file_id":"1CXohLk_LgIX94Cv-gBTlt0j9O5Wrs6AP","timestamp":1602131111093}],"private_outputs":true,"collapsed_sections":[],"mount_file_id":"1nAN_hNpKaHFAoxFXCv2aV72yC8Eyrn76","authorship_tag":"ABX9TyMo1CxGN1n4m+z76A3SkmBZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ODmm6FOAmOWM"},"source":["# 런타임유형 GPU로 변경, 상단 우측에 수정가능 왼쪽에 '연결' 클릭 => ram, 디스크표시\n","# 왼쪽 메뉴에서 구글드라이브 마운트 클릭\n","import tensorflow as tf\n","\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0TZiFi9-y03"},"source":["!pip uninstall tensorflow\n","!pip install tensorflow==1.15 # 1.15 버전 Tensorflow 설치\n","# 런타임 다시 실행"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SVTwFpC2GTXx"},"source":["## 성능평가 (Precision, Recall, Accuracy, F1-score)\n","- sklearn, metric\n","\n","### `classification_report(, , ,)`"]},{"cell_type":"code","metadata":{"id":"Z-5GPEhs4oLh"},"source":["from sklearn.metrics import classification_report\n","\n","y_true = [0, 1, 2, 2, 2]  # 정답, one hot 말고 label 형태\n","y_pred = [0, 0, 2, 2, 1]  # 우리 model이 예측한 값\n","\n","target_name = ['thin', 'normal', 'fat']\n","\n","print(classification_report(y_true, y_pred, target_names=target_name))\n","# - 첫번째 인자 : **t값(정답)** - 1차원 array\n","#   - Multinomial인 경우 one-hot으로 2차원이라면 1차원으로 변경해야 한다.\n","# - 두번째 인자 : **pred (예측)** - 1차원 array\n","# - 세번째 인자 : 출력 시 label을 표현하기 위한 문자열\n","\n","\n","# precision : true로 분류한 것 중 맞는 것\n","#   - thin의 precision 0.5 : 1/2 (0으로 예측하고 정답이 0 / 0으로 예측) \n","# recall : 실제 true인 것 중 model이 ture로 예측한 것\n","#   - thin의 recall이 1.0 : 1/1  (정답이 0이고 0으로 예측 / 정답이 0)\n","# thin의 support 1 => 정답 중 thin이 몇개 있는 지, 데이터 편향을 알 수 있다.\n","\n","# Accuracy : 맞는 예측 (TP + TN) / 모둔 경우 \n","#   - 가장 직관적이나, domain에 대한 bias가 존재한다.\n","#   \t- 질병에 걸릴 확률은 잘 찾아내나, 희귀병은 잘 찾아내지 못하는 경우"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t0j9tP0IGEju"},"source":["### `confusion_matrix`\n"]},{"cell_type":"code","metadata":{"id":"TJsjYIk2w94L"},"source":["from sklearn.metrics import confusion_matrix\n","\n","y_true = [2, 0, 2, 2, 0, 1]\n","y_pred = [0, 0, 2, 2, 0, 2]\n","\n","confusion_matrix(y_true, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6vMiB4nSIjmE"},"source":["![image](/content/drive/My Drive/MachineLearning/image/201008_01.jpg)"]},{"cell_type":"code","metadata":{"id":"K8UqQKUdIm2I"},"source":["%reset\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import seaborn as sns  # confusion matrix heatmap을 통해서 그래프 출력\n","from sklearn.preprocessing import MinMaxScaler # Normalization\n","from sklearn.model_selection import train_test_split # train, test 분리\n","from sklearn.model_selection import KFold # Cross Validation\n","from sklearn.metrics import classification_report, confusion_matrix \n","\n","tf.reset_default_graph()\n","\n","# Tensorflow 1.15버전을 가지고 MNIST예제를 구현\n","\n","# 1. Raw Data Loading\n","df = pd.read_csv('/content/drive/My Drive/MachineLearning/data/mnist/train.csv')\n","# display(df.head(), df.shape) # (42000, 785)\n","\n","# 2. 결측치와 이상치 처리\n","# 결측치를 찾고 만약 결측치가 존재하면 수정\n","# 이상치를 찾고 만약 이상치가 있으면 수정 - scipy의 zcore 이용 등등\n","# MNIST에는 결측치와 이상치가 존재하지 않는다.\n","\n","# 3. 사용하는 데이터가 이미지 데이터이기에, 어떤 이미지인지 확인해본다.\n","# df에서 label column은 제외하고 pixel 데이터만 들고온다.\n","img_data = df.drop('label', axis=1, inplace=False).values\n","\n","# 이미지들의 pixel 데이터만 ndarray로 추출 (2차원)\n","# 이런 이미지 데이터를 화면에 출력한다.\n","fig = plt.figure()  # 출력할 전체 화면을 지칭하는 객체를 가져온다.\n","# fig안에 subplot을 만든다. 이 subplot을 저장할 list를 만든다.\n","fig_arr = list()\n","\n","for n in range(10):\n","  fig_arr.append(fig.add_subplot(2, 5, n+1)) # 2행 5열, n+1번째\n","  fig_arr[n].imshow(img_data[n].reshape(28, 28), cmap='Greys',\n","                    interpolation='nearest')\n","  # interpolation='nearest'\n","  # 디스플레이 해상도가 이미지 해상도 (대부분의 경우)와 같지 않은 경우 \n","  # 픽셀을 보간하지 않고 이미지를 표시\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# 4. Data Split\n","#   데이터는 크게 3부분으로 나누어야 한다.\n","#   일단 2부분으로 나눈다 - train, test 용\n","#     train 데이터를 다시 2부분으로 나눈다. -train, validation\n","#       - train : 학습용 / 반복 학습으로 모델을 완성\n","#       - validation : 모델 수정용도의 데이터 셋\n","# train_test_split(독립변수, 종속변수 순)\n","x_data_train, x_data_test, t_data_train, t_data_test = \\\n","train_test_split(df.drop('label', axis=1), df['label'], test_size=0.3,\n","                 random_state=0)\n","\n","# 5. Normalization (x_data, 독립변수의 처리)\n","scaler = MinMaxScaler()   # 객체 생성\n","scaler.fit(x_data_train)  # 객체에 정보를 제공\n","x_data_train_norm = scaler.transform(x_data_train)\n","x_data_test_norm = scaler.transform(x_data_test)\n","\n","del x_data_train\n","del x_data_test\n","\n","# 6. 지금 해결해야 하는 문제는 multinomial이다.\n","# t_data (label 데이터, 정답)을 one hot 형태로 변경\n","\n","# Tensorflow node를 실행하기 위해서 session을 생성\n","sess = tf.Session() \n","\n","# depth는 label의 종류 개수\n","t_data_train_onehot = sess.run(tf.one_hot(t_data_train, depth=10))\n","t_data_test_onehot = sess.run(tf.one_hot(t_data_test, depth=10))\n","\n","######################### 데이터가 준비되었다. #########################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pn2eKgJ7L0zF"},"source":["# test용 데이터\n","test = pd.read_csv('/content/drive/My Drive/MachineLearning/data/mnist/test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JLW-oBZiE1Ok"},"source":["# Tesorflow 구현\n","# 1. placeholder\n","# X의 의미는 x_data (독립변수)를 받아들이기 위한 placeholder\n","X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n","T = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n","\n","# 2. Weight, bias\n","W = tf.Variable(tf.random.normal([784,10]), name='weight')\n","b = tf.Variable(tf.random.normal([10]), name='bias') # 로지스틱 10개\n","\n","# 3. Model (Hypothesis) => Multinomial\n","logit = tf.matmul(X, W) + b   # Linear Regression\n","H = tf.nn.softmax(logit)      # Multinomial Hypothesis\n","\n","# 4. loss function\n","loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n","                                                                 labels=T))\n","\n","# 5. Optimizer를 이용한 train (Optimizer는 loss값을 줄이는 알고리즘)\n","train = tf.train.GradientDescentOptimizer(learning_rate = 1e-1).minimize(loss)\n","\n","# 6. 학습용 parameter setting (기본적으로는 2개는 설정)\n","num_of_epoch = 1000\n","batch_size = 100\n","\n","# 7. 학습 진행\n","def run_train(sess, train_x, train_t):\n","  print('### 학습 시작 ###')\n","  sess.run(tf.global_variables_initializer()) # tf.Variable 초기화 (W, b)\n","\n","  # print(train_x.shape) # (29400, 784)\n","  total_batch = int(train_x.shape[0] / batch_size)\n","  for step in range(num_of_epoch):\n","\n","    for i in range(total_batch):\n","      batch_x = train_x[i*batch_size:(i+1)*batch_size]\n","      batch_t = train_t[i*batch_size:(i+1)*batch_size]\n","      _, loss_val = sess.run([train,loss], feed_dict={X:batch_x,\n","                                                      T:batch_t})\n","\n","    if step % 100 == 0:\n","      print('Loss : {}'.format(loss_val))\n","  print(\"### 학습 끝 ### \")\n","\n","# Accuracy\n","predict = tf.argmax(H, 1)   # [[0.1 0.3 0.2  .. 0.1]]\n","\n","# sklearn을 이용해서 classifaction_report를 출력\n","target_name = ['num 0', 'num 1', 'num 2', 'num 3', \n","               'num 4', 'num 5', 'num 6', 'num 7', \n","               'num 8', 'num 9']\n","    \n","### train 데이터로 학습하고 train 데이터로 성능 평가 해 보기\n","\n","run_train(sess, x_data_train_norm, t_data_train_onehot)\n","# classification_report(정답, 예측, 출력 label)\n","print(classification_report(t_data_train, \n","                            sess.run(predict, feed_dict={X:x_data_train_norm}),\n","                            target_names=target_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6mdeyynWO9i"},"source":["# test 예측\n","predict_result = sess.run([H, predict], feed_dict={X:test})\n","display(predict_result)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0LllU8zYPq-z"},"source":["predict_result[1].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cNkeCpENP4m8"},"source":["# 제출 파일\n","df = pd.read_csv('/content/drive/My Drive/MachineLearning/data/mnist/sample_submission.csv')\n","\n","ImageId = pd.DataFrame(df['ImageId'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lY_35ZL_PiWE"},"source":["# 제출 파일\n","submission = pd.DataFrame({\n","        \"ImageId\": ImageId['ImageId'],\n","        \"Label\": predict_result[1]\n","})\n","\n","submission.to_csv('/content/drive/My Drive/MachineLearning/data/mnist/submission.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r1gaOK03P5kF"},"source":["df = pd.read_csv('/content/drive/My Drive/MachineLearning/data/mnist/submission.csv')\n","display(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2bw4sV7wRDsp"},"source":["![image.png]('/content/drive/My Drive/MachineLearning/data/mnist/submission.PNG')"]}]}