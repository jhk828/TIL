{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# 버전 확인\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6695528  0.1078963 ]\n",
      " [0.23725594 0.18586521]]\n",
      "tf.Tensor([-0.38180086], shape=(1,), dtype=float32)\n",
      "[-0.38180086]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 랜덤값을 하나 얻어온다.\n",
    "\n",
    "# 1) Numpy\n",
    "random1 = np.random.rand(2,2)\n",
    "print(random1)\n",
    "\n",
    "# 2) Tensorflow\n",
    "random2 = tf.random.normal([1], dtype=tf.float32)\n",
    "print(random2) # Tensor가 출력된다.\n",
    "\n",
    "# TF 1.x 버전에서는 Node가 가지는 값을 얻어오려면 ( Node를 실행시키려면) Sessiond이 있어야 했다.\n",
    "# TF 2.x 버전에서는 session 없이 즉시 실행시킬 수 있다. -> Eager Execution\n",
    "print(random2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c의 값은 : 30.0\n",
      "60.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(10, dtype=tf.float32)\n",
    "b = tf.constant(20, dtype=tf.float32)\n",
    "\n",
    "c = a + b\n",
    "# numpy()라는 함수로 세션의 값을 얻는다.\n",
    "print('c의 값은 : {}'.format(c.numpy()))\n",
    "\n",
    "d = 30.0\n",
    "# 1차원 scalar 값을 tensor로 변환한다.\n",
    "tensor_d = tf.convert_to_tensor(d)\n",
    "print((c + tensor_d).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21090215]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1]), name='weight')\n",
    "\n",
    "# 기존에는 tf.Variable()을 이용해서 변수를 만들면 사용하기 전에 반드시 초기화를 진행해야 했다.\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# TF 2.0에서는 초기화를 하지 않아도 된다.\n",
    "print(W.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow graph에 입력을 주는 부분이 없어졌다.\n",
    "# 기존에는 graph에게 데이터를 밀어넣기 위해 placeholder를 이용했다. \n",
    "# 이를 Lazy exection이라 부른다.\n",
    "# TF 2.0에는 Eager Execution에 의해서 더이상 placeholder를 사용하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow의 keras를 이용하여 Model 생성\n",
    "\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.model import Sequential\n",
    "\n",
    "# model = Sequential()  # keras model 생성\n",
    "model = tf.keras.models.Sequential()  # 1. keras model 생성\n",
    "\n",
    "# 2. model을 만들었으니 그 다음에는 layer 생성\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(2, )))     # layer를 추가\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax')) # output이 3개\n",
    "\n",
    "# 3. model compile 과정\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def my_loss:\n",
    "    pass\n",
    "\n",
    "# model 학습\n",
    "model.fit(x_data_train,\n",
    "          t_data_train,\n",
    "          epochs=100,\n",
    "          batch_size=100,\n",
    "          validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow의 keras를 이용하여 Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 6)\n",
      "Ozone      37\n",
      "Solar.R     7\n",
      "Wind        0\n",
      "Temp        0\n",
      "Month       0\n",
      "Day         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Tensorflow 2.1을 이용해서 Ozone 예제 다시 구현\n",
    "# Multiple Linear Regression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # Model\n",
    "# 입력 / 출력 Layer - Flatten / Dense\n",
    "from tensorflow.keras.layers import Flatten, Dense # Layer\n",
    "# Gradient Descent의 종류 지정 - SGD\n",
    "from tensorflow.keras.optimizers import SGD # Optimizer\n",
    "from sklearn.preprocessing import MinMaxScaler  # Normalization\n",
    "from scipy import stats  # 이상치 처리\n",
    "\n",
    "# 1. Raw Data Loading\n",
    "df = pd.read_csv('./data/ozone.csv')\n",
    "\n",
    "# 2. 결측치 확인 및 처리\n",
    "# 일단 데이터가 충분하지 않고 결측치가 적으면 삭제한다.\n",
    "# 하지만 일반적으로 결측치를 삭제하면 데이터가 너무 많이 유실되기 때문에 다른 방식 이용\n",
    "print(df.shape) # (153, 6)\n",
    "print(df.isnull().sum()) # column별로 결측 몇개인지 확인\n",
    "# Ozone      37\n",
    "# Solar.R     7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9845\n",
      "0.998\n"
     ]
    }
   ],
   "source": [
    "# KNN 사용법 - sklearn\n",
    "\n",
    "# BMI 예제를 학습한 후 정확도 측정\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/bmi.csv', skiprows=3)\n",
    "\n",
    "# data split\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df[['height','weight']], \n",
    "                 df['label'], \n",
    "                 test_size=0.3, \n",
    "                 random_state=0)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train)\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_data_train_norm, t_data_train)\n",
    "print(model.score(x_data_test_norm, t_data_test))\n",
    "\n",
    "# KNN을 이용한 분류\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(x_data_train_norm, t_data_train)\n",
    "print(knn_model.score(x_data_test_norm, t_data_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_tensorflow2]",
   "language": "python",
   "name": "conda-env-data_env_tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
